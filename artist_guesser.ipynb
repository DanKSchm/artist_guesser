{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a function that exctracts all lyrics from an artist and store it in a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chosen/needed url's:https://www.lyrics.com/artist/Lana-Del-Rey/2487752\n",
    "                    https://www.lyrics.com/artist/a-ha/3491\n",
    "                    https://www.lyrics.com/artist/blink-182/211247"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lyrics (url):\n",
    "    \n",
    "    \"\"\"\n",
    "    - get artist page from links: artist_links -> artist_pages\n",
    "    - extract links from the artist page: artist_pages -> artist_song_links\n",
    "    - downloads links from the song page: song_links -> song_pages\n",
    "    - extract lyrcis from the song page: song_pages -> lyrics_list\n",
    "    - cleans the lyrics, returns a list of lyrics: lyrics_list -> clean_lyrics_list\n",
    "    \"\"\"\n",
    "    r = requests.get(url)\n",
    "    regex = r'a\\shref=\"(\\/lyric\\/.+?)\"'\n",
    "    matches = re.findall(regex, r.text)\n",
    "\n",
    "    song_links = []\n",
    "\n",
    "    for i in matches:\n",
    "        full_link = \"http://www.lyrics.com\"+ i\n",
    "        song_links.append(full_link)\n",
    "\n",
    "    lyric_html = []\n",
    "\n",
    "    for song_link in song_links: #here we can define how much links we want to extract after song_links[]\n",
    "        time.sleep(1)\n",
    "        resp = requests.get(song_link)\n",
    "        lyric_html.append(resp.text)\n",
    "     \n",
    "    lyrics = []\n",
    "\n",
    "    for lyric_html_string in lyric_html:\n",
    "        soup = BeautifulSoup(lyric_html_string, \"html.parser\")\n",
    "        #lyrics_raw.append(soup)\n",
    "        songtext = soup.select(\"#lyric-body-text\")\n",
    "        songtext = songtext[0].get_text()\n",
    "        lyrics.append(songtext) \n",
    "         \n",
    "    final_artist_lyric_list = []\n",
    "    replace_items =[\".\", \";\", \"—\", \"_\", '“', \":\", \"\\n\", \"(\", \")\", \"?\", \"\\\\\",\",\", \"()\", \"'\", \",\"]\n",
    "    \n",
    "    \n",
    "    for lyric in lyrics:\n",
    "        lyric_lowercase = lyric.lower().strip()\n",
    "        \n",
    "    \n",
    "        for item in replace_items:\n",
    "            lyric_lowercase = lyric_lowercase.replace(item, \" \")\n",
    "        final_artist_lyric_list.append(lyric_lowercase)\n",
    "    \n",
    "    return final_artist_lyric_list\n",
    "        \n",
    "#pac = get_lyrics(\"https://www.lyrics.com/artist/2Pac/50051\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(pac))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert lyrics to PandaDataFrame, save as CSV and add Artist name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_pddf (lyrics_from_artist, artistname, filename):\n",
    "    data = {\"songtext\": lyrics_from_artist, \"artist\": artistname}\n",
    "    lyrics = pd.DataFrame(data)\n",
    "    lyrics.to_csv(filename)\n",
    "    return lyrics\n",
    "\n",
    "#convert_to_pddf(pac, \"2pac\", \"2pac.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>songtext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A_ha</td>\n",
       "      <td>we re talking away\\r i don t know what\\r i m t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A_ha</td>\n",
       "      <td>we re talking away i don t know what i m to sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A_ha</td>\n",
       "      <td>sometimes the way we talk isn t all that good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A_ha</td>\n",
       "      <td>hold me tight this is a lonely night and i ve ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A_ha</td>\n",
       "      <td>i ll never let you see the way my broken heart...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                                           songtext\n",
       "0   A_ha  we re talking away\\r i don t know what\\r i m t...\n",
       "1   A_ha  we re talking away i don t know what i m to sa...\n",
       "2   A_ha  sometimes the way we talk isn t all that good ...\n",
       "3   A_ha  hold me tight this is a lonely night and i ve ...\n",
       "4   A_ha  i ll never let you see the way my broken heart..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('data/a_ha.csv', index_col=[0])\n",
    "df2=pd.read_csv('data/blink182.csv', index_col=[0])\n",
    "df3=pd.read_csv('data/lanadelrey.csv', index_col=[0])\n",
    "df4=pd.read_csv(\"data/2pac.csv\", index_col=[0])\n",
    "\n",
    "df1 = df1.append(df2)\n",
    "df1 = df1.append(df3)\n",
    "df1 = df1.append(df4)\n",
    "\n",
    "all_artists_lyrics = df1[[\"artist\",\"songtext\"]]\n",
    "all_artists_lyrics.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2pac            1242\n",
       "A_ha            1189\n",
       "Blink182         930\n",
       "Lana_del_Rey     514\n",
       "Name: artist, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_artists_lyrics.artist.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_artists_lyrics[\"artist_label\"] = all_artists_lyrics.artist.map({\"A_ha\": 0, \"Blink182\": 1,\"Lana_del_Rey\": 2})\n",
    "\n",
    "#all_artists_lyrics.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3875,)\n",
      "(3875,)\n"
     ]
    }
   ],
   "source": [
    "X = all_artists_lyrics.songtext\n",
    "y = all_artists_lyrics.artist   # store the feature matrix (X) and response vector (y)\n",
    "\n",
    "print(X.shape)                  # check the shapes of X and y\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2906,)\n",
      "(969,)\n",
      "(2906,)\n",
      "(969,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer( stop_words='english',max_df=0.90,min_df=2 ) \n",
    "# import and instantiate CountVectorizer (with the default parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2906x9010 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 276749 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(X_train)   # learn the 'vocabulary' of the training data\n",
    "\n",
    "vect.get_feature_names()      # examine the fitted vocabulary\n",
    "\n",
    "X_train_dtm = vect.transform(X_train)  # transform training data into a 'document-term matrix'\n",
    "X_train_dtm               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dtm.toarray()       #convert sparse matrix to a dense matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>04</th>\n",
       "      <th>10</th>\n",
       "      <th>106</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>122nd</th>\n",
       "      <th>125</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>...</th>\n",
       "      <th>zero</th>\n",
       "      <th>zig</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipped</th>\n",
       "      <th>zodiac</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zow</th>\n",
       "      <th>zulu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2902</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2904</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2905</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2906 rows × 9010 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      04  10  106  11  12  122nd  125  13  14  15  ...  zero  zig  zip  \\\n",
       "0      0   0    0   0   0      0    0   0   0   0  ...     0    0    0   \n",
       "1      0   0    0   0   0      0    0   0   0   0  ...     0    0    0   \n",
       "2      0   0    0   0   0      0    0   0   0   0  ...     0    0    0   \n",
       "3      0   0    0   0   0      0    0   0   0   0  ...     0    0    0   \n",
       "4      0   0    0   0   0      0    0   0   0   0  ...     0    0    0   \n",
       "...   ..  ..  ...  ..  ..    ...  ...  ..  ..  ..  ...   ...  ...  ...   \n",
       "2901   0   0    0   0   0      0    0   0   0   0  ...     0    0    0   \n",
       "2902   0   0    0   0   1      0    0   0   0   0  ...     0    0    0   \n",
       "2903   0   0    0   0   0      0    0   0   0   0  ...     0    0    0   \n",
       "2904   0   0    0   0   0      0    0   0   0   0  ...     0    0    0   \n",
       "2905   0   0    0   0   0      0    0   0   0   0  ...     0    0    0   \n",
       "\n",
       "      zipped  zodiac  zone  zones  zoo  zow  zulu  \n",
       "0          0       0     0      0    0    0     0  \n",
       "1          0       0     0      0    0    0     0  \n",
       "2          0       0     0      0    0    0     0  \n",
       "3          0       0     0      0    0    0     0  \n",
       "4          0       0     0      0    0    0     0  \n",
       "...      ...     ...   ...    ...  ...  ...   ...  \n",
       "2901       0       0     0      0    0    0     0  \n",
       "2902       0       0     0      0    0    0     0  \n",
       "2903       0       0     0      0    0    0     0  \n",
       "2904       0       0     0      0    0    0     0  \n",
       "2905       0       0     0      0    0    0     0  \n",
       "\n",
       "[2906 rows x 9010 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_dtm.toarray(), columns=vect.get_feature_names())  #examine the vocabulary and document-term matrix together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<969x9010 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 91879 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_dtm = vect.transform(X_test)   # transform test data into a 'document-term matrix'\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model (The multinomial Naive Bayes classifier is suitable for classification with discrete features.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time nb.fit(X_train_dtm, y_train)        # train the model using X_train_dtm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = nb.predict(X_test_dtm)     # make class predictions for X_test_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save models on harddisk with pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pickle', 'wb') as f:\n",
    "    pickle.dump(nb, f)\n",
    "    \n",
    "with open('vectorizer.pickle', 'wb') as f:\n",
    "    pickle.dump(vect, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9803921568627451"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred_class)   # calculate accuracy of class predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[310,   1,   1,   2],\n",
       "       [  2, 318,   1,   1],\n",
       "       [  3,   3, 209,   2],\n",
       "       [  0,   3,   0, 113]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred_class)      # print the confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testtext = [\"I was walking in the rain\"]        \n",
    "\n",
    "testtext_dtm = vect.transform(testtext)\n",
    "predicttt = nb.predict_proba(testtext_dtm)\n",
    "\n",
    "print(predicttt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build input function for user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type in any text: I need a smoke\n",
      "['2pac']\n",
      "[[0.76163326 0.00898368 0.16171476 0.0676683 ]]\n",
      " This lyric snatch fits best to the artist ['2pac'] with a probability of 0.7616332588665898\n"
     ]
    }
   ],
   "source": [
    "testtext = input(\"Please type in any text: \")\n",
    "\n",
    "testtext_dtm = vect.transform([testtext])\n",
    "which_artist = nb.predict(testtext_dtm)\n",
    "prob_artist = nb.predict_proba(testtext_dtm)\n",
    "\n",
    "print(which_artist)\n",
    "print(prob_artist)\n",
    "\n",
    "print(\" This lyric snatch fits best to the artist \" + str(which_artist) + \" with a probability of \" +  str(max(prob_artist[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
